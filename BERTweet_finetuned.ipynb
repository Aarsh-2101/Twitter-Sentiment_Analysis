{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e94b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb2b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11271 entries, 0 to 11270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11271 non-null  object\n",
      " 1   label   11271 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 176.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dfo = pd.read_csv('data/obama_cleaned.csv')\n",
    "dfo = dfo.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "dfr = pd.read_csv('data/romney_cleaned.csv')\n",
    "dfr = dfr.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "df = pd.concat([dfo, dfr], ignore_index = True)\n",
    "df.info()\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "697deb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'text' : 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f1d5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11271 entries, 0 to 11270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11271 non-null  string\n",
      " 1   label   11271 non-null  int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 176.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77694489",
   "metadata": {},
   "source": [
    "# Pre-trained model: BERTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed82996",
   "metadata": {},
   "source": [
    "Fine-tuning using our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19350299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    405\n",
       "-1    404\n",
       " 1    316\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xo = dfo['text']\n",
    "yo = dfo['label']\n",
    "Xo, Xo_test, yo, yo_test = train_test_split(Xo, yo, test_size = 0.2)\n",
    "Xo_train, Xo_eval, yo_train, yo_eval = train_test_split(Xo, yo, test_size = 0.25)\n",
    "Xr = dfr['text']\n",
    "yr = dfr['label']\n",
    "Xr, Xr_test, yr, yr_test = train_test_split(Xr, yr, test_size = 0.2)\n",
    "Xr_train, Xr_eval, yr_train, yr_eval = train_test_split(Xo, yo, test_size = 0.25)\n",
    "\n",
    "\n",
    "traindf_o = pd.concat([Xo_train,yo_train], axis = 1)\n",
    "traindf_r = pd.concat([Xr_train,yr_train], axis = 1)\n",
    "evaldf_o = pd.concat([Xo_eval,yo_eval], axis = 1)\n",
    "evaldf_r = pd.concat([Xr_eval,yr_eval], axis = 1)\n",
    "testdf_o = pd.concat([Xo_test,yo_test], axis = 1)\n",
    "testdf_r = pd.concat([Xr_test,yr_test], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1736875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o = Dataset.from_pandas(traindf_o, split = 'train')\n",
    "eval_o = Dataset.from_pandas(evaldf_o, split = 'eval')\n",
    "test_o = Dataset.from_pandas(testdf_o, split = 'test')\n",
    "train_r = Dataset.from_pandas(traindf_r, split = 'train')\n",
    "eval_r = Dataset.from_pandas(evaldf_r, split = 'eval')\n",
    "test_r = Dataset.from_pandas(testdf_r, split = 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91bef167",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63abfcd2c2e346d4a1ae2ab3484c5001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8ae3f9a8e2498384f9ef3103985edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadec3dc409448ae916ab6161f19fb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085a407bbdd84ee5b6dbe806f15a8644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44a66a562b44550ba3d84444a7940ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8188dc3ed24d57bb7fa27c0c81df79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1130 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_train_o = train_o.map(tokenize_function, batched=True)\n",
    "tokenized_eval_o = eval_o.map(tokenize_function, batched=True)\n",
    "tokenized_test_o = test_o.map(tokenize_function, batched=True)\n",
    "tokenized_train_r = train_r.map(tokenize_function, batched=True)\n",
    "tokenized_eval_r = eval_o.map(tokenize_function, batched=True)\n",
    "tokenized_test_r = test_r.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6065f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "226119b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7a6de4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6172908544540405, 'eval_accuracy': 0.4444444444444444, 'eval_runtime': 11.7037, 'eval_samples_per_second': 96.123, 'eval_steps_per_second': 12.047, 'epoch': 1.0}\n",
      "{'loss': 0.3784, 'learning_rate': 4.259478672985782e-05, 'epoch': 1.18}\n",
      "{'eval_loss': 0.39306536316871643, 'eval_accuracy': 0.512, 'eval_runtime': 11.4746, 'eval_samples_per_second': 98.043, 'eval_steps_per_second': 12.288, 'epoch': 2.0}\n",
      "{'loss': 0.2631, 'learning_rate': 3.518957345971564e-05, 'epoch': 2.37}\n",
      "{'eval_loss': 0.4201142489910126, 'eval_accuracy': 0.5164444444444445, 'eval_runtime': 11.4244, 'eval_samples_per_second': 98.474, 'eval_steps_per_second': 12.342, 'epoch': 3.0}\n",
      "{'loss': 0.1607, 'learning_rate': 2.778436018957346e-05, 'epoch': 3.55}\n",
      "{'eval_loss': 0.538033664226532, 'eval_accuracy': 0.5137777777777778, 'eval_runtime': 11.3675, 'eval_samples_per_second': 98.967, 'eval_steps_per_second': 12.404, 'epoch': 4.0}\n",
      "{'loss': 0.0858, 'learning_rate': 2.037914691943128e-05, 'epoch': 4.74}\n",
      "{'eval_loss': 0.6635199785232544, 'eval_accuracy': 0.5022222222222222, 'eval_runtime': 11.756, 'eval_samples_per_second': 95.696, 'eval_steps_per_second': 11.994, 'epoch': 5.0}\n",
      "{'loss': 0.0422, 'learning_rate': 1.2973933649289099e-05, 'epoch': 5.92}\n",
      "{'eval_loss': 0.8200305700302124, 'eval_accuracy': 0.5137777777777778, 'eval_runtime': 11.4593, 'eval_samples_per_second': 98.174, 'eval_steps_per_second': 12.304, 'epoch': 6.0}\n",
      "{'eval_loss': 0.862837016582489, 'eval_accuracy': 0.5048888888888889, 'eval_runtime': 11.1719, 'eval_samples_per_second': 100.699, 'eval_steps_per_second': 12.621, 'epoch': 7.0}\n",
      "{'loss': 0.0286, 'learning_rate': 5.56872037914692e-06, 'epoch': 7.11}\n",
      "{'eval_loss': 0.8999069929122925, 'eval_accuracy': 0.5057777777777778, 'eval_runtime': 11.6104, 'eval_samples_per_second': 96.896, 'eval_steps_per_second': 12.144, 'epoch': 8.0}\n",
      "{'train_runtime': 1323.6464, 'train_samples_per_second': 20.392, 'train_steps_per_second': 2.551, 'train_loss': 0.14492685506694125, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3376, training_loss=0.14492685506694125, metrics={'train_runtime': 1323.6464, 'train_samples_per_second': 20.392, 'train_steps_per_second': 2.551, 'train_loss': 0.14492685506694125, 'epoch': 8.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_o = TrainingArguments(output_dir=\"checkpoints/test_trainer_o\", evaluation_strategy=\"epoch\", num_train_epochs=8)\n",
    "trainer_o = Trainer(\n",
    "    model=model_o,\n",
    "    args=training_args_o,\n",
    "    train_dataset=tokenized_train_o,\n",
    "    eval_dataset=tokenized_eval_o,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_o.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c04dde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_o.save_model('models/model_obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47697b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25792068243026733, 'eval_accuracy': 0.5466666666666666, 'eval_runtime': 11.2133, 'eval_samples_per_second': 100.327, 'eval_steps_per_second': 12.574, 'epoch': 1.0}\n",
      "{'loss': 0.3632, 'learning_rate': 4.259478672985782e-05, 'epoch': 1.18}\n",
      "{'eval_loss': 0.20618405938148499, 'eval_accuracy': 0.5724444444444444, 'eval_runtime': 11.3791, 'eval_samples_per_second': 98.866, 'eval_steps_per_second': 12.391, 'epoch': 2.0}\n",
      "{'loss': 0.25, 'learning_rate': 3.518957345971564e-05, 'epoch': 2.37}\n",
      "{'eval_loss': 0.2009427696466446, 'eval_accuracy': 0.5884444444444444, 'eval_runtime': 11.6067, 'eval_samples_per_second': 96.927, 'eval_steps_per_second': 12.148, 'epoch': 3.0}\n",
      "{'loss': 0.1604, 'learning_rate': 2.778436018957346e-05, 'epoch': 3.55}\n",
      "{'eval_loss': 0.18442708253860474, 'eval_accuracy': 0.6088888888888889, 'eval_runtime': 11.3957, 'eval_samples_per_second': 98.722, 'eval_steps_per_second': 12.373, 'epoch': 4.0}\n",
      "{'loss': 0.0774, 'learning_rate': 2.037914691943128e-05, 'epoch': 4.74}\n",
      "{'eval_loss': 0.18587228655815125, 'eval_accuracy': 0.608, 'eval_runtime': 11.5267, 'eval_samples_per_second': 97.6, 'eval_steps_per_second': 12.233, 'epoch': 5.0}\n",
      "{'loss': 0.0473, 'learning_rate': 1.2973933649289099e-05, 'epoch': 5.92}\n",
      "{'eval_loss': 0.19022423028945923, 'eval_accuracy': 0.608, 'eval_runtime': 11.4444, 'eval_samples_per_second': 98.302, 'eval_steps_per_second': 12.32, 'epoch': 6.0}\n",
      "{'eval_loss': 0.1941012591123581, 'eval_accuracy': 0.6097777777777778, 'eval_runtime': 11.3427, 'eval_samples_per_second': 99.183, 'eval_steps_per_second': 12.431, 'epoch': 7.0}\n",
      "{'loss': 0.0269, 'learning_rate': 5.56872037914692e-06, 'epoch': 7.11}\n",
      "{'eval_loss': 0.19562079012393951, 'eval_accuracy': 0.6088888888888889, 'eval_runtime': 11.306, 'eval_samples_per_second': 99.505, 'eval_steps_per_second': 12.471, 'epoch': 8.0}\n",
      "{'train_runtime': 1330.9679, 'train_samples_per_second': 20.28, 'train_steps_per_second': 2.537, 'train_loss': 0.13952911267348375, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3376, training_loss=0.13952911267348375, metrics={'train_runtime': 1330.9679, 'train_samples_per_second': 20.28, 'train_steps_per_second': 2.537, 'train_loss': 0.13952911267348375, 'epoch': 8.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_r = TrainingArguments(output_dir=\"checkpoints/test_trainer_r\", evaluation_strategy=\"epoch\", num_train_epochs=8)\n",
    "trainer_r = Trainer(\n",
    "    model=model_r,\n",
    "    args=training_args_r,\n",
    "    train_dataset=tokenized_train_r,\n",
    "    eval_dataset=tokenized_eval_r,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_r.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c1d77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_r.save_model('models/model_romney')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbd0c0",
   "metadata": {},
   "source": [
    "# Load from checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_o\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_o = TrainingArguments(output_dir=\"test_trainer_o\", evaluation_strategy=\"epoch\", num_train_epochs=5)\n",
    "trainer_o = Trainer(\n",
    "    model=model_o,\n",
    "    args=training_args_o,\n",
    "    train_dataset=tokenized_train_o,\n",
    "    eval_dataset=tokenized_test_o,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_o.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_r\", num_labels=3)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_r = TrainingArguments(output_dir=\"checkpoints/test_trainer_r\", evaluation_strategy=\"epoch\", num_train_epochs=8)\n",
    "trainer_r = Trainer(\n",
    "    model=model_r,\n",
    "    args=training_args_r,\n",
    "    train_dataset=tokenized_train_r,\n",
    "    eval_dataset=tokenized_eval_r,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_r.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91159b0d",
   "metadata": {},
   "source": [
    "# Load finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6400df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained('models/model_obama')\n",
    "model_r = AutoModelForSequenceClassification.from_pretrained('models/model_romney')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ebdad76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe_o = TextClassificationPipeline(model=model_o, tokenizer=tokenizer)\n",
    "pipe_r = TextClassificationPipeline(model=model_o, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d66d5c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos = list()\n",
    "neg = list()\n",
    "neu = list()\n",
    "pred_o = pd.DataFrame()\n",
    "for t in testdf_o['text']:\n",
    "    pred = pipe_o(t, top_k=None)\n",
    "    for l in pred:\n",
    "        if l['label'] == 'POS':\n",
    "            pos.append(l['score'])\n",
    "        elif l['label'] == 'NEG':\n",
    "            neg.append(l['score'])\n",
    "        else: \n",
    "            neu.append(l['score'])\n",
    "\n",
    "pred_o['pos'] = pos\n",
    "pred_o['neg'] = neg\n",
    "pred_o['neu'] = neu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "276fbe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list()\n",
    "neg = list()\n",
    "neu = list()\n",
    "pred_r = pd.DataFrame()\n",
    "for t in testdf_r['text']:\n",
    "    pred = pipe_r(t, top_k=None)\n",
    "    for l in pred:\n",
    "        if l['label'] == 'POS':\n",
    "            pos.append(l['score'])\n",
    "        elif l['label'] == 'NEG':\n",
    "            neg.append(l['score'])\n",
    "        else: \n",
    "            neu.append(l['score'])\n",
    "\n",
    "pred_r['pos'] = pos\n",
    "pred_r['neg'] = neg\n",
    "pred_r['neu'] = neu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91251f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pred</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.998849</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.999264</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.997420</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pos       neg       neu  pred  class\n",
       "0  0.000055  0.999480  0.000465    -1     -1\n",
       "1  0.000136  0.000239  0.999625     0      1\n",
       "2  0.000023  0.999250  0.000727    -1     -1\n",
       "3  0.000095  0.999494  0.000412    -1      0\n",
       "4  0.000010  0.001140  0.998849     0      1\n",
       "5  0.000005  0.004108  0.995888     0     -1\n",
       "6  0.000029  0.999301  0.000670    -1     -1\n",
       "7  0.000033  0.999264  0.000703    -1      0\n",
       "8  0.000088  0.999487  0.000424    -1      0\n",
       "9  0.000007  0.997420  0.002573    -1     -1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_o['class'] = list(yo_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5160006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_r['class'] = list(yr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc575a6",
   "metadata": {},
   "source": [
    "# Predict label using maximum probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6dfd0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_label(df):\n",
    "    preds = list()\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['pos'] >= row['neu'] and row['pos'] >= row['neg']:\n",
    "            preds.append(1)\n",
    "        elif row['neg'] >= row['neu'] and row['neg'] > row['pos']:\n",
    "            preds.append(-1)\n",
    "        elif row['neu'] > row['pos'] and row['neu'] > row['neg']:\n",
    "            preds.append(0)\n",
    "    df['pred'] = preds\n",
    "    acc = accuracy_score(df['class'], df['pred'])\n",
    "    prec = precision_score(df['class'], df['pred'], average = None, zero_division = np.nan)\n",
    "    rec = recall_score(df['class'], df['pred'], average = None)\n",
    "    f1 = f1_score(df['class'], df['pred'], average = None)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1:\", f1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6722c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29333333333333333\n",
      "Precision: [0.44358578 0.08995816        nan]\n",
      "Recall: [0.7175     0.11345646 0.        ]\n",
      "F1: [0.54823305 0.10035006 0.        ]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_o = pred_label(pred_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "86cef8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4451327433628319\n",
      "Precision: [0.56387097 0.18591549        nan]\n",
      "Recall: [0.7319933  0.19760479 0.        ]\n",
      "F1: [0.63702624 0.191582   0.        ]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_r = pred_label(pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb34cfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    775\n",
       " 0    355\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels_r['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53285580",
   "metadata": {},
   "source": [
    "# Predict label using ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, parameters, X, y, n_splits):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state = 27)\n",
    "    avg_accuracies = list()\n",
    "    avg_precisions = list()\n",
    "    avg_recalls = list()\n",
    "    avg_f1s = list()\n",
    "    confs = list()\n",
    "    for conf in ParameterGrid(parameters):\n",
    "        print('Testing', conf)\n",
    "        accuracies = list()\n",
    "        precisions = list()\n",
    "        recalls = list()\n",
    "        f1s = list()\n",
    "        i = 1\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            try:\n",
    "                model.set_params(**conf)\n",
    "                model.fit(X_train, y_train)\n",
    "            except:\n",
    "                print('Skipped', conf)\n",
    "                break\n",
    "            print('\\tFold', i, 'of', n_splits)\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            precisions.append(precision_score(y_test, y_pred, average=None, zero_division = np.nan))\n",
    "            recalls.append(recall_score(y_test, y_pred, average=None, zero_division = np.nan))\n",
    "            f1s.append(f1_score(y_test, y_pred, average=None, zero_division = np.nan))\n",
    "            if i == 1:\n",
    "                confs.append(conf)\n",
    "            i = i + 1\n",
    "            \n",
    "    \n",
    "        if len(accuracies) != 0:  \n",
    "            avg_accuracies.append(sum(accuracies)/len(accuracies))\n",
    "            avg_precisions.append((sum(precisions)/len(precisions)) if len(precisions) > 0 else np.nan)\n",
    "            avg_recalls.append(sum(recalls)/len(recalls) if len(recalls) > 0 else np.nan)\n",
    "            avg_f1s.append(sum(f1s)/len(f1s) if len(f1s) > 0 else np.nan)\n",
    "        \n",
    "    results = {'Parameters' : confs,\n",
    "              'Accuracy' : avg_accuracies,\n",
    "              'Precision' : avg_precisions,\n",
    "              'Recall' : avg_recalls,\n",
    "              'F1' : avg_f1s}\n",
    "    \n",
    "    return pd.DataFrame.from_dict(results), model.classes_\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['pos', 'neg', 'neu']]\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9632f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svm = {'C' : (0.1, 1, 10, 100),\n",
    "             'kernel' : ('rbf', 'poly', 'linear'),\n",
    "             'degree' : (3, 5, 7),\n",
    "             'gamma' : ('scale', 'auto')}\n",
    "svm = SVC()\n",
    "svm_results, cl_svm = test_model(svm, params_svm, X_train, y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee787bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc36d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928dfca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_rf = {'n_estimators' : (50, 100, 150),\n",
    "            'criterion' : ('entropy', 'gini'),\n",
    "            'max_features' : (None, 'sqrt')}\n",
    "rf = RandomForestClassifier()\n",
    "rf_results, cl_rf = test_model(rf, params_rf, X_train, y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841135c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c874d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b55142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_knn = {'n_neighbors' : (1, 3, 5, 7, 9),\n",
    "             'metric' : ('minkowski', 'euclidean', 'manhattan', 'cosine')}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_results, cl_knn = test_model(knn, params_knn, X_train, y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1b270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {'penalty' : ('l1', 'l2', 'elasticnet', None),\n",
    "            'C' : (0.1, 1, 10, 100),\n",
    "            'solver' : ('lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'),\n",
    "            'max_iter' : [500]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_results, cl_lr = test_model(lr, params_lr, X_train, y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8266b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d52d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
